{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gradient Boosting and XGBoost\n",
    "\n",
    "I will be creating models using Sklearn's Gradient Boost, and the XGBoost algorithm."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "# Importing Required Packages.\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Training labels\n",
    "training_labels = pd.read_csv('../../Data/training_set_labels.csv', index_col='respondent_id')\n",
    "training_features = pd.read_csv('../../Data/training_set_features.csv', index_col='respondent_id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "# TTS\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_features, training_labels['h1n1_vaccine'], test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preproccessing\n",
    "For the preproccessing, all of the columns are categorical, however, some of them are numerical, and some of them are strings. We will want to handle these these columns differently when imputing missing values.\n",
    "\n",
    "- Numerical Categories\n",
    "    - Use Sklearn's Iterative Imputer to fill in the missing values\n",
    "- String Categories\n",
    "    - Fill missing values with a new value: 'unknown'\n",
    "    - One hot encode the results\n",
    "- Categories with more then 10 unique categories\n",
    "    - We will frequency code these instead, so we don't have an overwhelming amount of columns in the dataframe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "# Preproccessing columns\n",
    "num_cols = []\n",
    "ohe_cols = []\n",
    "freq_cols = []\n",
    "\n",
    "# Seperate columns into numerical, categorical, and freq\n",
    "for c in training_features.columns:\n",
    "    if training_features[c].dtype in ['float64', 'int64']:\n",
    "        num_cols.append(c)\n",
    "    elif training_features[c].nunique() < 10:\n",
    "        ohe_cols.append(c)\n",
    "    else:\n",
    "        freq_cols.append(c)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "# Scale the data using a MinMax scaler, and fill NaN values with the mean\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('num_imputer', IterativeImputer(max_iter=15)),\n",
    "])\n",
    "\n",
    "# Onehot Encoding transformer for Categorical variable\n",
    "ohe_transformer = Pipeline(steps=[\n",
    "    ('ohe_imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('oh_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Transformer for categories with more then 10 unique values\n",
    "freq_transformer = Pipeline(steps=[\n",
    "    ('freq_encoder', ce.count.CountEncoder(normalize=True, min_group_size=.05)),\n",
    "    ('freq_imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "# Combine transformers into preprocessor.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('ohe', ohe_transformer, ohe_cols),\n",
    "        ('freq', freq_transformer, freq_cols)\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Slearn Gradient Boost\n",
    "Here I will create a baseline gradient boost model to compare future models too."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gb_clf', GradientBoostingClassifier())\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([8.74792504, 7.67256904, 8.15417767, 7.3578949 , 8.5042932 ]),\n 'score_time': array([0.09879994, 0.12452102, 0.11120009, 0.09787178, 0.204777  ]),\n 'test_score': array([0.85331098, 0.84772283, 0.85219335, 0.85159307, 0.8529905 ])}"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate test\n",
    "cross_validate(clf, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.854\n",
      "recall: 0.486\n",
      "f1: 0.585\n",
      "roc_auc: 0.719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "clf.fit(X_train, y_train)\n",
    "_preds = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print('accuracy: {:0.3f}'.format(accuracy_score(y_test, _preds)))\n",
    "print('recall: {:0.3f}'.format(recall_score(y_test, _preds)))\n",
    "print('f1: {:0.3f}'.format(f1_score(y_test, _preds)))\n",
    "print('roc_auc: {:0.3f}'.format(roc_auc_score(y_test , _preds)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "accuracy: 0.854\n",
    "recall: 0.486\n",
    "f1: 0.585\n",
    "roc_auc: 0.719"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}