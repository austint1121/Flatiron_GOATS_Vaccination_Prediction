{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gradient Boosting and XGBoost\n",
    "\n",
    "I will be creating models using Sklearn's Gradient Boost, and the XGBoost algorithm."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Importing Required Packages.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Training labels\n",
    "training_labels = pd.read_csv('../../Data/training_set_labels.csv', index_col='respondent_id')\n",
    "training_features = pd.read_csv('../../Data/training_set_features.csv', index_col='respondent_id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def metrics(y_test, _preds):\n",
    "    print('accuracy: {:0.3f}'.format(accuracy_score(y_test, _preds)))\n",
    "    print('recall: {:0.3f}'.format(recall_score(y_test, _preds)))\n",
    "    print('f1: {:0.3f}'.format(f1_score(y_test, _preds)))\n",
    "    print('roc_auc: {:0.3f}'.format(roc_auc_score(y_test , _preds)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# TTS\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_features, training_labels['h1n1_vaccine'], test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preproccessing\n",
    "For the preproccessing, all of the columns are categorical, however, some of them are numerical, and some of them are strings. We will want to handle these these columns differently when imputing missing values.\n",
    "\n",
    "- Numerical Categories\n",
    "    - Use Sklearn's Iterative Imputer to fill in the missing values\n",
    "- String Categories\n",
    "    - Fill missing values with a new value: 'unknown'\n",
    "    - One hot encode the results\n",
    "- Categories with more then 10 unique categories\n",
    "    - We will frequency code these instead, so we don't have an overwhelming amount of columns in the dataframe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Preproccessing columns\n",
    "num_cols = []\n",
    "ohe_cols = []\n",
    "freq_cols = []\n",
    "\n",
    "# Seperate columns into numerical, categorical, and freq\n",
    "for c in training_features.columns:\n",
    "    if training_features[c].dtype in ['float64', 'int64']:\n",
    "        num_cols.append(c)\n",
    "    elif training_features[c].nunique() < 10:\n",
    "        ohe_cols.append(c)\n",
    "    else:\n",
    "        freq_cols.append(c)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Fill NaN values using IterativeImputer\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('num_imputer', IterativeImputer(max_iter=15)),\n",
    "])\n",
    "\n",
    "# Onehot Encoding transformer for Categorical variable\n",
    "ohe_transformer = Pipeline(steps=[\n",
    "    ('ohe_imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('oh_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Transformer for categories with more then 10 unique values\n",
    "freq_transformer = Pipeline(steps=[\n",
    "    ('freq_encoder', ce.count.CountEncoder(normalize=True, min_group_size=.05)),\n",
    "    ('freq_imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Combine transformers into preprocessor.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('ohe', ohe_transformer, ohe_cols),\n",
    "        ('freq', freq_transformer, freq_cols)\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sklearn Gradient Boost\n",
    "Here I will create a baseline gradient boost model to compare future models too."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gb_clf', GradientBoostingClassifier())\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([7.06111097, 7.50069499, 6.69995785, 6.82990289, 6.00017095]),\n 'score_time': array([0.09743404, 0.10969114, 0.10481215, 0.10366416, 0.08387303]),\n 'test_score': array([0.85331098, 0.84772283, 0.85219335, 0.85159307, 0.8529905 ])}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate test\n",
    "cross_validate(clf, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.854\n",
      "recall: 0.486\n",
      "f1: 0.585\n",
      "roc_auc: 0.719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "clf.fit(X_train, y_train)\n",
    "_preds = clf.predict(X_test)\n",
    "\n",
    "metrics(y_test, _preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "accuracy: 0.854\n",
    "recall: 0.486\n",
    "f1: 0.585\n",
    "roc_auc: 0.719"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost\n",
    "Let's try a baseline model for XGBoost as well.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "XG_clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gb_clf', XGBClassifier(eval_metric='auc'))\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([7.23860407, 6.64287996, 8.49426484, 7.9869628 , 6.65491295]),\n 'score_time': array([0.13163996, 0.25379586, 0.13175607, 0.23549294, 0.12765408]),\n 'test_score': array([0.85079631, 0.84353171, 0.84353171, 0.84041364, 0.84684181])}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(XG_clf, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "XG_clf.fit(X_train, y_train)\n",
    "boost_preds = XG_clf.predict(X_test)\n",
    "metrics(y_test, boost_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.845\n",
      "recall: 0.513\n",
      "f1: 0.584\n",
      "roc_auc: 0.724\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}